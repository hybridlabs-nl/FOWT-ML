{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "33f0d675-bda0-4700-b494-3a1ac492e20b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fowt_ml.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9668aa7e-d4b0-4029-8f51-2600484cbe99",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_config_file = \"../../src/example_config.yml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "336fe93e-1c1d-4139-8bba-d9bf40ff85bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_pipeline = Pipeline(example_config_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d723305b-6614-43ad-afd8-54a4e534ceb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set correct path for mat file\n",
    "my_pipeline.config[\"data\"][\"exp699\"][\"mat_file\"] = \"../../../data/example/exp699.mat\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "65883373-0964-4d01-88f4-74fcac69517e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 327702 entries, 0 to 327701\n",
      "Columns: 125 entries, time to wind_speed\n",
      "dtypes: float64(125)\n",
      "memory usage: 312.5 MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>acc_calc6[0]</th>\n",
       "      <th>acc_calc6[1]</th>\n",
       "      <th>acc_calc6[2]</th>\n",
       "      <th>acc_calc6[3]</th>\n",
       "      <th>acc_calc6[4]</th>\n",
       "      <th>acc_calc6[5]</th>\n",
       "      <th>acc_tb_meas3[0]</th>\n",
       "      <th>acc_tb_meas3[1]</th>\n",
       "      <th>acc_tb_meas3[2]</th>\n",
       "      <th>...</th>\n",
       "      <th>spd_rot_cmd</th>\n",
       "      <th>time_wave_precalc</th>\n",
       "      <th>tq_mot_act</th>\n",
       "      <th>trig_Hex_in</th>\n",
       "      <th>trig_PIV_in</th>\n",
       "      <th>trig_PIV_out</th>\n",
       "      <th>wtm2_spd_rot_act</th>\n",
       "      <th>wtm2_spd_tor_cmd</th>\n",
       "      <th>wtm2_tq_mot_act</th>\n",
       "      <th>wind_speed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.580219</td>\n",
       "      <td>0.135577</td>\n",
       "      <td>0.070342</td>\n",
       "      <td>-0.757244</td>\n",
       "      <td>-2.295318</td>\n",
       "      <td>-0.619591</td>\n",
       "      <td>-1.032135</td>\n",
       "      <td>0.214810</td>\n",
       "      <td>9.635009</td>\n",
       "      <td>...</td>\n",
       "      <td>474.0</td>\n",
       "      <td>29.406</td>\n",
       "      <td>-17.928282</td>\n",
       "      <td>0.999695</td>\n",
       "      <td>-0.000488</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-470.274464</td>\n",
       "      <td>-474.0</td>\n",
       "      <td>40.714927</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.001000</td>\n",
       "      <td>-2.035639</td>\n",
       "      <td>0.705470</td>\n",
       "      <td>0.066672</td>\n",
       "      <td>-4.331129</td>\n",
       "      <td>-5.214741</td>\n",
       "      <td>-0.165520</td>\n",
       "      <td>-2.268602</td>\n",
       "      <td>-0.458810</td>\n",
       "      <td>7.425536</td>\n",
       "      <td>...</td>\n",
       "      <td>474.0</td>\n",
       "      <td>29.407</td>\n",
       "      <td>-29.986389</td>\n",
       "      <td>0.999969</td>\n",
       "      <td>-0.000336</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-471.326827</td>\n",
       "      <td>-474.0</td>\n",
       "      <td>24.651387</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.001999</td>\n",
       "      <td>-2.114400</td>\n",
       "      <td>-0.785931</td>\n",
       "      <td>-0.044466</td>\n",
       "      <td>5.023345</td>\n",
       "      <td>-5.750528</td>\n",
       "      <td>-0.520829</td>\n",
       "      <td>-1.588994</td>\n",
       "      <td>-1.485706</td>\n",
       "      <td>6.823769</td>\n",
       "      <td>...</td>\n",
       "      <td>474.0</td>\n",
       "      <td>29.408</td>\n",
       "      <td>-14.466384</td>\n",
       "      <td>0.999695</td>\n",
       "      <td>-0.000610</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-499.477522</td>\n",
       "      <td>-474.0</td>\n",
       "      <td>38.891995</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.003000</td>\n",
       "      <td>-2.179736</td>\n",
       "      <td>0.086170</td>\n",
       "      <td>0.448392</td>\n",
       "      <td>-0.444052</td>\n",
       "      <td>-6.337631</td>\n",
       "      <td>0.078678</td>\n",
       "      <td>0.279178</td>\n",
       "      <td>-1.889878</td>\n",
       "      <td>6.000455</td>\n",
       "      <td>...</td>\n",
       "      <td>474.0</td>\n",
       "      <td>29.409</td>\n",
       "      <td>-22.535783</td>\n",
       "      <td>0.999084</td>\n",
       "      <td>-0.000214</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-470.800646</td>\n",
       "      <td>-474.0</td>\n",
       "      <td>25.997681</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.004000</td>\n",
       "      <td>-1.792539</td>\n",
       "      <td>-0.315190</td>\n",
       "      <td>0.253570</td>\n",
       "      <td>2.065519</td>\n",
       "      <td>-3.999853</td>\n",
       "      <td>0.206758</td>\n",
       "      <td>-1.349485</td>\n",
       "      <td>-1.129436</td>\n",
       "      <td>8.111131</td>\n",
       "      <td>...</td>\n",
       "      <td>474.0</td>\n",
       "      <td>29.410</td>\n",
       "      <td>-14.566729</td>\n",
       "      <td>0.999695</td>\n",
       "      <td>-0.000092</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-471.589917</td>\n",
       "      <td>-474.0</td>\n",
       "      <td>29.576647</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 125 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       time  acc_calc6[0]  acc_calc6[1]  acc_calc6[2]  acc_calc6[3]  \\\n",
       "0  0.000000     -1.580219      0.135577      0.070342     -0.757244   \n",
       "1  0.001000     -2.035639      0.705470      0.066672     -4.331129   \n",
       "2  0.001999     -2.114400     -0.785931     -0.044466      5.023345   \n",
       "3  0.003000     -2.179736      0.086170      0.448392     -0.444052   \n",
       "4  0.004000     -1.792539     -0.315190      0.253570      2.065519   \n",
       "\n",
       "   acc_calc6[4]  acc_calc6[5]  acc_tb_meas3[0]  acc_tb_meas3[1]  \\\n",
       "0     -2.295318     -0.619591        -1.032135         0.214810   \n",
       "1     -5.214741     -0.165520        -2.268602        -0.458810   \n",
       "2     -5.750528     -0.520829        -1.588994        -1.485706   \n",
       "3     -6.337631      0.078678         0.279178        -1.889878   \n",
       "4     -3.999853      0.206758        -1.349485        -1.129436   \n",
       "\n",
       "   acc_tb_meas3[2]  ...  spd_rot_cmd  time_wave_precalc  tq_mot_act  \\\n",
       "0         9.635009  ...        474.0             29.406  -17.928282   \n",
       "1         7.425536  ...        474.0             29.407  -29.986389   \n",
       "2         6.823769  ...        474.0             29.408  -14.466384   \n",
       "3         6.000455  ...        474.0             29.409  -22.535783   \n",
       "4         8.111131  ...        474.0             29.410  -14.566729   \n",
       "\n",
       "   trig_Hex_in  trig_PIV_in  trig_PIV_out  wtm2_spd_rot_act  wtm2_spd_tor_cmd  \\\n",
       "0     0.999695    -0.000488           0.0       -470.274464            -474.0   \n",
       "1     0.999969    -0.000336           0.0       -471.326827            -474.0   \n",
       "2     0.999695    -0.000610           0.0       -499.477522            -474.0   \n",
       "3     0.999084    -0.000214           0.0       -470.800646            -474.0   \n",
       "4     0.999695    -0.000092           0.0       -471.589917            -474.0   \n",
       "\n",
       "   wtm2_tq_mot_act  wind_speed  \n",
       "0        40.714927         4.0  \n",
       "1        24.651387         4.0  \n",
       "2        38.891995         4.0  \n",
       "3        25.997681         4.0  \n",
       "4        29.576647         4.0  \n",
       "\n",
       "[5 rows x 125 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the data\n",
    "df = my_pipeline.get_data(\"exp699\")\n",
    "df.info()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "02cdd9e1-a550-4678-83c3-42e372605dce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'target': ['acc_tb_meas3[0]',\n",
       "  'acc_tb_meas3[1]',\n",
       "  'acc_tb_meas3[2]',\n",
       "  'acc_tt_meas3[0]',\n",
       "  'acc_tt_meas3[1]',\n",
       "  'acc_tt_meas3[2]',\n",
       "  'force_aero_est6[0]',\n",
       "  'force_aero_est6[1]',\n",
       "  'force_aero_est6[2]',\n",
       "  'force_aero_est6[3]',\n",
       "  'force_aero_est6[4]',\n",
       "  'force_aero_est6[5]',\n",
       "  'force_tt_meas6[0]',\n",
       "  'force_tt_meas6[1]',\n",
       "  'force_tt_meas6[2]',\n",
       "  'force_tt_meas6[3]',\n",
       "  'force_tt_meas6[4]',\n",
       "  'force_tt_meas6[5]'],\n",
       " 'predictors': ['pos_act6[0]',\n",
       "  'pos_act6[1]',\n",
       "  'pos_act6[2]',\n",
       "  'pos_act6[3]',\n",
       "  'pos_act6[4]',\n",
       "  'pos_act6[5]',\n",
       "  'spd_rot_act',\n",
       "  'wind_speed'],\n",
       " 'save_grid_scores': True,\n",
       " 'save_best_model': True,\n",
       " 'n_jobs': 2,\n",
       " 'use_gpu': False,\n",
       " 'train_size': 0.7,\n",
       " 'models': ['en', 'lar', 'llar', 'lasso', 'lr', 'ridge', 'omp', 'ransac'],\n",
       " 'metrics_sort': 'R2',\n",
       " 'system_log': './logs.log'}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# inspect ML setup\n",
    "my_pipeline.config[\"ml_setup\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "03987d96-eb24-4d7b-972b-7d5b1688ed67",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.linear_model import Lars, Lasso, Ridge\n",
    "from sklearn.metrics import root_mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a34cba8b-4f34-4e0d-adf6-725087c6fa1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_log_model(model, model_name, batch_size=None):\n",
    "    with mlflow.start_run():\n",
    "        X_batch, y_batch = X_train, y_train\n",
    "        if batch_size != None:\n",
    "            X_batch, y_batch = X_train[:batch_size], y_train[:batch_size]\n",
    "\n",
    "        # Train the model\n",
    "        model.fit(X_batch, y_batch)\n",
    "        \n",
    "        # Predict the target\n",
    "        y_pred = model.predict(X_test)\n",
    "        \n",
    "        # Log model parameters and metrics\n",
    "        mlflow.log_param(\"model_name\", model_name)\n",
    "        mlflow.log_param(\"n_estimators\", model.n_estimators if hasattr(model, 'n_estimators') else None)\n",
    "        mlflow.log_param(\"max_depth\", model.max_depth if hasattr(model, 'max_depth') else None)\n",
    "        \n",
    "        # Calculate and log the performance metrics\n",
    "        rmse = root_mean_squared_error(y_test, y_pred)\n",
    "        mlflow.log_metric(\"rmse\", rmse)\n",
    "        \n",
    "        # Log the model itself\n",
    "        mlflow.sklearn.log_model(model, model_name)\n",
    "        \n",
    "        return rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "23b1a399-6026-4705-bf67-24bfad96a43a",
   "metadata": {},
   "outputs": [],
   "source": [
    "gbr = HistGradientBoostingRegressor(\n",
    "    # loss='squared_error',\n",
    "    # learning_rate=0.1,\n",
    "    max_iter=50,\n",
    "    # max_leaf_nodes=31,\n",
    "    max_depth=9,\n",
    "    # min_samples_leaf=20,\n",
    "    # l2_regularization=0.0,\n",
    "    # max_features=3.0,           # ?\n",
    "    # max_bins=255,\n",
    "    # warm_start=False,\n",
    "    # early_stopping='auto',\n",
    "    # scoring='loss',\n",
    "    # validation_fraction=0.1,\n",
    "    # n_iter_no_change=10,\n",
    "    # tol=1e-07,\n",
    ")\n",
    "\n",
    "models = [\n",
    "    (MultiOutputRegressor(gbr, n_jobs=18), \"GradientBoostingRegressor\"),\n",
    "    (Lars(), \"LeastAngleRegression\"),\n",
    "    (Lasso(), \"LassoRegression\"),\n",
    "    (Ridge(), \"RidgeRegression\")\n",
    "]\n",
    "\n",
    "# Note, gradient boosting does not natively support multi-target output. Use sklearn.multioutput.MultiOutputRegressor(estimator, *, n_jobs=None)\n",
    "\n",
    "\n",
    "# Francesco used the following for RF EnsembleModel(estimator=\"RandomForest\", max_depth=9, max_samples=10_000, n_estimators=50)\n",
    "# Other potentially valuable arguments are max_leaf_nodes (instead of max_depth), learning_rate <= 0.1 (interacts strongly with n_estimators; set n_estimators \"large enough\"), subsample (eg 0.5), max_features (eg 2 or 3)\n",
    "# for HistGBR, n_estimators captured by max_iter\n",
    "\n",
    "# Dictionary to store model performances\n",
    "model_performances = {}\n",
    "\n",
    "predictors_labels = my_pipeline.config[\"ml_setup\"][\"predictors\"]\n",
    "target_labels = my_pipeline.config[\"ml_setup\"][\"target\"]\n",
    "\n",
    "X_data = df[predictors_labels]\n",
    "Y_data = df[target_labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "14442af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_data, Y_data, test_size=0.75, shuffle=False, random_state=123) # TODO set test_size to 0.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "988c26b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(81925, 8)\n",
      "(81925, 18)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b03891d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0efeb415",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m2025/01/30 15:17:00 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "runtime GradientBoostingRegressor: 0:00:09.487316\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m2025/01/30 15:17:03 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "runtime LeastAngleRegression: 0:00:03.596855\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m2025/01/30 15:17:07 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "runtime LassoRegression: 0:00:03.621780\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m2025/01/30 15:17:10 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "runtime RidgeRegression: 0:00:03.487690\n",
      "{'GradientBoostingRegressor': 3.6287607149205225, 'LeastAngleRegression': 3.5914625711937265, 'LassoRegression': 3.733306142704239, 'RidgeRegression': 3.5914586161568707}\n",
      "CPU times: user 4.91 s, sys: 293 ms, total: 5.2 s\n",
      "Wall time: 20.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Train, log models, and compare performance\n",
    "for model, name in models:\n",
    "    start_time = datetime.datetime.now()\n",
    "    rmse = train_and_log_model(model, name)\n",
    "    model_performances[name] = rmse\n",
    "    end_time = datetime.datetime.now()\n",
    "    print(f\"runtime {name}: {end_time-start_time}\")\n",
    "print(model_performances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "cb78a5c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m2025/01/30 15:23:40 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.627843637426277\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m2025/01/30 15:23:54 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.629074429163094\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m2025/01/30 15:24:10 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.6277775420779244\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m2025/01/30 15:24:26 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.6268734098960738\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m2025/01/30 15:24:40 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.6262581453004876\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m2025/01/30 15:24:53 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.62643473384315\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m2025/01/30 15:25:06 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.6284647309358493\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m2025/01/30 15:25:20 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.6278193471500426\n",
      "14.3 s ± 937 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "\n",
    "model = MultiOutputRegressor(\n",
    "    HistGradientBoostingRegressor(\n",
    "        # loss='squared_error',\n",
    "        # learning_rate=0.1,\n",
    "        max_iter=50,\n",
    "        # max_leaf_nodes=31,\n",
    "        max_depth=9,\n",
    "        # min_samples_leaf=20,\n",
    "        # l2_regularization=0.0,\n",
    "        # max_features=3.0,           # ?\n",
    "        # max_bins=255,\n",
    "        # warm_start=False,\n",
    "        # early_stopping='auto',\n",
    "        # scoring='loss',\n",
    "        # validation_fraction=0.1,\n",
    "        # n_iter_no_change=10,\n",
    "        # tol=1e-07,\n",
    "    ),\n",
    "    n_jobs=1\n",
    ")\n",
    "name = \"GradientBoostingRegressor\"\n",
    "\n",
    "rmse = train_and_log_model(model, name)\n",
    "print(rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "72e5edf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m2025/01/30 15:25:36 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.6289860869231316\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m2025/01/30 15:25:46 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.6263484958202588\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m2025/01/30 15:25:57 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.624900808635564\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m2025/01/30 15:26:11 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.6298826504232533\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m2025/01/30 15:26:24 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.623949765540734\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m2025/01/30 15:26:35 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.6293084466944134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m2025/01/30 15:26:47 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.625807129146841\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m2025/01/30 15:26:59 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.6266515230196115\n",
      "11.8 s ± 1.19 s per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "\n",
    "model = MultiOutputRegressor(\n",
    "    HistGradientBoostingRegressor(\n",
    "        # loss='squared_error',\n",
    "        # learning_rate=0.1,\n",
    "        max_iter=50,\n",
    "        # max_leaf_nodes=31,\n",
    "        max_depth=9,\n",
    "        # min_samples_leaf=20,\n",
    "        # l2_regularization=0.0,\n",
    "        # max_features=3.0,           # ?\n",
    "        # max_bins=255,\n",
    "        # warm_start=False,\n",
    "        # early_stopping='auto',\n",
    "        # scoring='loss',\n",
    "        # validation_fraction=0.1,\n",
    "        # n_iter_no_change=10,\n",
    "        # tol=1e-07,\n",
    "    ),\n",
    "    n_jobs=18\n",
    ")\n",
    "name = \"GradientBoostingRegressor\"\n",
    "\n",
    "rmse = train_and_log_model(model, name)\n",
    "print(rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "33611ad9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m2025/01/30 15:27:11 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.6261840330739568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m2025/01/30 15:27:22 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.627059526181602\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m2025/01/30 15:27:33 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.625578832128361\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m2025/01/30 15:27:45 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.628246587106668\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m2025/01/30 15:27:57 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.6282208771967834\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m2025/01/30 15:28:11 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.624757427113047\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m2025/01/30 15:28:25 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.629724578519978\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m2025/01/30 15:28:39 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.625310498052794\n",
      "12.6 s ± 1.41 s per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "\n",
    "model = MultiOutputRegressor(\n",
    "    HistGradientBoostingRegressor(\n",
    "        # loss='squared_error',\n",
    "        # learning_rate=0.1,\n",
    "        max_iter=50,\n",
    "        # max_leaf_nodes=31,\n",
    "        max_depth=9,\n",
    "        # min_samples_leaf=20,\n",
    "        # l2_regularization=0.0,\n",
    "        # max_features=3.0,           # ?\n",
    "        # max_bins=255,\n",
    "        # warm_start=False,\n",
    "        # early_stopping='auto',\n",
    "        # scoring='loss',\n",
    "        # validation_fraction=0.1,\n",
    "        # n_iter_no_change=10,\n",
    "        # tol=1e-07,\n",
    "    ),\n",
    "    n_jobs=-1\n",
    ")\n",
    "name = \"GradientBoostingRegressor\"\n",
    "\n",
    "rmse = train_and_log_model(model, name)\n",
    "print(rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e03519e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m2025/01/30 15:57:40 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.5925059567096502\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m2025/01/30 15:57:47 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.59259151296365\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m2025/01/30 15:57:54 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.5931670760210985\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m2025/01/30 15:58:01 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.592742220482834\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m2025/01/30 15:58:09 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.591676974245366\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m2025/01/30 15:58:17 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.59266392118389\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m2025/01/30 15:58:24 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.593001503058995\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m2025/01/30 15:58:32 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.592849810092114\n",
      "7.42 s ± 265 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "\n",
    "model = MultiOutputRegressor(\n",
    "    HistGradientBoostingRegressor(\n",
    "        # loss=\"squared_error\",\n",
    "        # quantile=None,\n",
    "        learning_rate=0.12,         # changed from default\n",
    "        max_iter=20,                # changed from default\n",
    "        # max_leaf_nodes=31,\n",
    "        max_depth=3,                # changed from default\n",
    "        # min_samples_leaf=20,\n",
    "        l2_regularization=0.0,\n",
    "        # max_features=1.0,\n",
    "        max_bins=255,\n",
    "        # warm_start=False,\n",
    "        # early_stopping=\"auto\",\n",
    "        # scoring=\"loss\",\n",
    "        # validation_fraction=0.1,\n",
    "        # n_iter_no_change=10,\n",
    "        # tol=1e-7,\n",
    "    ),\n",
    "    n_jobs=18\n",
    ")\n",
    "# Best so far:\n",
    "# model = MultiOutputRegressor(\n",
    "#     HistGradientBoostingRegressor(\n",
    "#         # loss=\"squared_error\",\n",
    "#         # quantile=None,\n",
    "#         learning_rate=0.12,         # changed from default\n",
    "#         max_iter=20,                # changed from default\n",
    "#         # max_leaf_nodes=31,\n",
    "#         max_depth=3,                # changed from default\n",
    "#         # min_samples_leaf=20,\n",
    "#         l2_regularization=0.0,\n",
    "#         # max_features=1.0,\n",
    "#         max_bins=255,\n",
    "#         # warm_start=False,\n",
    "#         # early_stopping=\"auto\",\n",
    "#         # scoring=\"loss\",\n",
    "#         # validation_fraction=0.1,\n",
    "#         # n_iter_no_change=10,\n",
    "#         # tol=1e-7,\n",
    "#     ),\n",
    "#     n_jobs=18\n",
    "# )\n",
    "# rmse ~= 3.592\n",
    "name = \"GradientBoostingRegressor\"\n",
    "\n",
    "rmse = train_and_log_model(model, name)\n",
    "print(rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "4524c290",
   "metadata": {},
   "outputs": [],
   "source": [
    "gbr = HistGradientBoostingRegressor(\n",
    "    learning_rate=0.12,\n",
    "    max_iter=20,\n",
    "    max_depth=3,\n",
    ")\n",
    "\n",
    "models = [\n",
    "    (MultiOutputRegressor(gbr, n_jobs=18), \"GradientBoostingRegressor\"),\n",
    "    (Lars(), \"LeastAngleRegression\"),\n",
    "    (Lasso(), \"LassoRegression\"),\n",
    "    (Ridge(), \"RidgeRegression\")\n",
    "]\n",
    "\n",
    "# Note, gradient boosting does not natively support multi-target output. Use sklearn.multioutput.MultiOutputRegressor(estimator, *, n_jobs=None)\n",
    "\n",
    "\n",
    "# Francesco used the following for RF EnsembleModel(estimator=\"RandomForest\", max_depth=9, max_samples=10_000, n_estimators=50)\n",
    "# Other potentially valuable arguments are max_leaf_nodes (instead of max_depth), learning_rate <= 0.1 (interacts strongly with n_estimators; set n_estimators \"large enough\"), subsample (eg 0.5), max_features (eg 2 or 3)\n",
    "# for HistGBR, n_estimators captured by max_iter\n",
    "\n",
    "# Dictionary to store model performances\n",
    "model_performances = {}\n",
    "\n",
    "predictors_labels = my_pipeline.config[\"ml_setup\"][\"predictors\"]\n",
    "target_labels = my_pipeline.config[\"ml_setup\"][\"target\"]\n",
    "\n",
    "X_data = df[predictors_labels]\n",
    "Y_data = df[target_labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "0ab3f185",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m2025/01/31 11:03:55 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "runtime GradientBoostingRegressor: 0:00:09.814222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m2025/01/31 11:04:02 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "runtime LeastAngleRegression: 0:00:06.542736\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m2025/01/31 11:04:08 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "runtime LassoRegression: 0:00:06.277909\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m2025/01/31 11:04:14 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "runtime RidgeRegression: 0:00:06.288213\n",
      "{'GradientBoostingRegressor': 3.592517164078976, 'LeastAngleRegression': 3.5914625711937265, 'LassoRegression': 3.733306142704239, 'RidgeRegression': 3.5914586161568707}\n",
      "CPU times: user 6.07 s, sys: 394 ms, total: 6.46 s\n",
      "Wall time: 28.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Train, log models, and compare performance\n",
    "for model, name in models:\n",
    "    start_time = datetime.datetime.now()\n",
    "    rmse = train_and_log_model(model, name)\n",
    "    model_performances[name] = rmse\n",
    "    end_time = datetime.datetime.now()\n",
    "    print(f\"runtime {name}: {end_time-start_time}\")\n",
    "print(model_performances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6176f6ee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hybridlabs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
